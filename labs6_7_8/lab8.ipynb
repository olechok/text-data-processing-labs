{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.314336Z",
     "start_time": "2025-05-12T18:19:31.308424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import csv\n",
    "import json"
   ],
   "id": "ddb5b183fb520a68",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.340625Z",
     "start_time": "2025-05-12T18:19:31.337635Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "b7ecedee8aac5c63",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/b_gg040147b_s7krqpc_nlcr0000gn/T/ipykernel_73813/3435192702.py:1: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.428802Z",
     "start_time": "2025-05-12T18:19:31.425284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_flights_dialogues(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_dialogues = json.load(f)\n",
    "\n",
    "    cleaned = []\n",
    "    for d in all_dialogues:\n",
    "        turns = [{'speaker': t['speaker'], 'utterance': t['utterance']} for t in d[\"turns\"]]\n",
    "        cleaned.append(turns)\n",
    "    return cleaned"
   ],
   "id": "51d3f1d86e961b4a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.462466Z",
     "start_time": "2025-05-12T18:19:31.456642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dialogues_to_pairs(cleaned_dialogues):\n",
    "    pairs = []\n",
    "    for dialogue in cleaned_dialogues:\n",
    "        for i in range(len(dialogue) - 1):\n",
    "            turn = dialogue[i]\n",
    "            next_turn = dialogue[i + 1]\n",
    "            if turn[\"speaker\"].upper() == \"USER\" and next_turn[\"speaker\"].upper() == \"SYSTEM\":\n",
    "                pairs.append({\n",
    "                    \"input_text\": turn[\"utterance\"],\n",
    "                    \"target_text\": next_turn[\"utterance\"]\n",
    "                })\n",
    "    return pairs"
   ],
   "id": "f7a1d943fbb0ff53",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.473673Z",
     "start_time": "2025-05-12T18:19:31.470854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_pairs_csv(pairs, csv_path):\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"input_text\", \"target_text\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(pairs)"
   ],
   "id": "beefe5e96fa83b32",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.490513Z",
     "start_time": "2025-05-12T18:19:31.486741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FlightsDialogueDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        source = item['input_text']\n",
    "        target = item['target_text']\n",
    "\n",
    "        source_enc = self.tokenizer(\n",
    "            source, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "        target_enc = self.tokenizer(\n",
    "            target, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        labels = target_enc['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  # Ignore padding\n",
    "\n",
    "        return {\n",
    "            'input_ids': source_enc['input_ids'].squeeze(),\n",
    "            'attention_mask': source_enc['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }"
   ],
   "id": "1df3293a7875329c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:45.271422Z",
     "start_time": "2025-05-12T18:19:45.265956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_t5_dialogue_model(pairs, model_name=\"t5-base\", output_dir=\"./t5-dialogue-model\", epochs=3, batch_size=2):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    train_dataset = FlightsDialogueDataset(pairs, tokenizer, max_length=64)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        save_steps=50,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=10\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset\n",
    "    )\n",
    "\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    print(f\"Model saved to {output_dir}\")"
   ],
   "id": "86d6423b8e787889",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.509679Z",
     "start_time": "2025-05-12T18:19:31.507188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_dir, device):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_dir).to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ],
   "id": "ba0aeaaeba890431",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:31.522122Z",
     "start_time": "2025-05-12T18:19:31.518965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_reply(model, tokenizer, context, device, max_length=50, num_beams=5):\n",
    "    inputs = tokenizer.encode(context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "3090d718693d8f67",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:19:49.399209Z",
     "start_time": "2025-05-12T18:19:49.393431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_path = \"flights.json\"\n",
    "csv_path = \"input_target_pairs.csv\"\n",
    "model_dir = \"./t5-dialogue-model\"\n",
    "\n",
    "# Step 1: Data preparation\n",
    "cleaned = load_flights_dialogues(json_path)\n",
    "pairs = dialogues_to_pairs(cleaned)\n",
    "save_pairs_csv(pairs, csv_path)\n",
    "\n",
    "# Step 2: Model fine-tuning\n",
    "train_t5_dialogue_model(pairs, output_dir=model_dir)\n",
    "\n",
    "# Step 3: Example inference\n",
    "model, tokenizer = load_model(model_dir, device)\n",
    "user_input = \"I want to find a one way flight from Seattle.\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "21c9a37d9b45b265",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:32:40.610773Z",
     "start_time": "2025-05-12T18:19:52.417315Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8c9192590676289d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olechka/Library/Caches/pypoetry/virtualenvs/lab6-t9ZM5Q0q-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='1116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1116/1116 12:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.706900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.908500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.766600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.494200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.997100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.864200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.572200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.137100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.731700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.138900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.863700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.608500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.922800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.884700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.850200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.631900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.956700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.498700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.636400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.612700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.819300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.628500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.784100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olechka/Library/Caches/pypoetry/virtualenvs/lab6-t9ZM5Q0q-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/olechka/Library/Caches/pypoetry/virtualenvs/lab6-t9ZM5Q0q-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./t5-dialogue-model\n",
      "User: I want to find a one way flight from Seattle.\n",
      "System: Where are you planning to go?\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:34:17.886869Z",
     "start_time": "2025-05-12T18:34:14.768180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = \"./t5-dialogue-model\"\n",
    "model, tokenizer = load_model(model_dir, device)"
   ],
   "id": "f97b7eacf4ec0ec1",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:34:20.133483Z",
     "start_time": "2025-05-12T18:34:19.351682Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I want to find a one way flight from Seattle.\n",
      "System: Where are you planning to go?\n"
     ]
    }
   ],
   "execution_count": 27,
   "source": [
    "user_input = \"I want to find a one way flight from Seattle.\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "b134be690cc2a8fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:34:28.871703Z",
     "start_time": "2025-05-12T18:34:27.881967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"I would like to fly with United Airlines. I will be leaving from NYC.\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "33e302dcb0a31537",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I would like to fly with United Airlines. I will be leaving from NYC.\n",
      "System: What date would you like to travel?\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T12:50:26.605943Z",
     "start_time": "2025-05-13T12:50:25.012209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"I want to travel next Wednesday\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "70883e5e9d5c7a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I want to travel next Wednesday\n",
      "System: Where are you planning to go?\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T12:52:29.179761Z",
     "start_time": "2025-05-13T12:52:26.871555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"A different airline please\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "94b7c9df4584b63e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: A different airline please\n",
      "System: Which airline would you like to fly with?\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:06:22.083141Z",
     "start_time": "2025-05-13T13:06:20.443481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"What is the weather like in Kyiv\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "fa4b11f502fcd05d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the weather like in Kyiv\n",
      "System: What is the weather like in Kyiv?\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T12:57:41.050149Z",
     "start_time": "2025-05-13T12:57:37.625200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"The model is pre-trained on the Colossal Clean Crawled Corpus (C4).\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "e923f5ba48877d7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: The model is pre-trained on the Colossal Clean Crawled Corpus (C4).\n",
      "System: The model is pre-trained on the Colossal Clean Crawled Corpus (C4).\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:06:41.044732Z",
     "start_time": "2025-05-13T13:06:39.360699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"How old are you?\"\n",
    "system_reply = generate_reply(model, tokenizer, user_input, device)\n",
    "print(\"User:\", user_input)\n",
    "print(\"System:\", system_reply)"
   ],
   "id": "2b687364a629395e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How old are you?\n",
      "System: How old are you?\n"
     ]
    }
   ],
   "execution_count": 86
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
